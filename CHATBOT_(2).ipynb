{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abissankar/ChatBot-KEC/blob/main/CHATBOT_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WChvlmCB1hNs"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q torch datasets accelerate peft bitsandbytes trl\n",
        "!pip install langchain playwright html2text sentence_transformers faiss-gpu gradio\n",
        "!pip install langchain-community\n",
        "!playwright install chromium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM\n",
        "import torch\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import AsyncChromiumLoader\n",
        "from langchain.document_transformers import Html2TextTransformer\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "import nest_asyncio\n",
        "import gradio as gr\n"
      ],
      "metadata": {
        "id": "RM4EW-Rj117z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "IWTcGHPh2CaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model\n",
        "model_name = \"HuggingFaceH4/zephyr-7b-beta\""
      ],
      "metadata": {
        "id": "gu9ZcJgZ2Lco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring model and Initializing tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n"
      ],
      "metadata": {
        "id": "6Jny0Q2V2RSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BitsAndBytes config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=False\n",
        ")"
      ],
      "metadata": {
        "id": "u-d7bP1C2TxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "67hq9Ze12ZWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the text generation pipeline\n",
        "text_generation_pipeline = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.0,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=300,\n",
        ")"
      ],
      "metadata": {
        "id": "nNMFIyFi2bVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup LangChain memory for conversation history\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\", return_messages=True)"
      ],
      "metadata": {
        "id": "DRdbPtdu2fC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"<|system|>\n",
        "You are an assistant knowledgeable about Kongu Engineering College.\n",
        "<|user|>\n",
        "Here is some context: {context}\n",
        "\n",
        "Question: {question}\n",
        "<|assistant|>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jDEU7ogB2hZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Create PromptTemplate object\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=prompt_template\n",
        ")"
      ],
      "metadata": {
        "id": "JQddXEg2CM56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize HuggingFacePipeline with the model\n",
        "zep_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
      ],
      "metadata": {
        "id": "15TWx0wE26UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the LLMChain\n",
        "llm_chain = LLMChain(llm=zep_llm, prompt=prompt, memory=memory)"
      ],
      "metadata": {
        "id": "Rdx1SwKR3S5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup embedding and retriever (for RAG)\n",
        "# Define the articles to scrape\n",
        "articles = [\n",
        "    \"https://en.wikipedia.org/wiki/Kongu_Engineering_College\",\n",
        "    \"https://www.kongu.edu/aboutus.html\"\n",
        "]"
      ],
      "metadata": {
        "id": "NI7CO73b3Tkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install playwright\n",
        "!playwright install chromium\n"
      ],
      "metadata": {
        "id": "GwP-VQIz5hYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrape the articles for context\n",
        "loader = AsyncChromiumLoader(articles)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "NhiZeR8k3Wt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install html2text\n",
        "!pip install faiss-cpu\n"
      ],
      "metadata": {
        "id": "nLtLj6eC6OQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert HTML to plain text\n",
        "html2text = Html2TextTransformer()\n",
        "docs_transformed = html2text.transform_documents(docs)"
      ],
      "metadata": {
        "id": "0ZOjH6be3ZFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk the text for indexing\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "chunked_documents = text_splitter.split_documents(docs_transformed)\n",
        "# Load chunked documents into FAISS index\n",
        "db = FAISS.from_documents(chunked_documents, HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))"
      ],
      "metadata": {
        "id": "X3CwtmVg3bdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert FAISS into a retriever\n",
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={'k': 4})"
      ],
      "metadata": {
        "id": "ul9D9vKT3fAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio interface to interact with the chatbot\n",
        "def chatbot_interaction(context, question):\n",
        "    # If no context provided, retrieve from RAG setup\n",
        "    if not context.strip():\n",
        "        docs = retriever.get_relevant_documents(question)\n",
        "        context = \"\\n\".join([doc.page_content for doc in docs])\n",
        "        # Interact with the chatbot\n",
        "    query_data = {\"context\": context, \"question\": question, \"human_input\": question}\n",
        "    response = llm_chain.invoke(query_data)\n",
        "    return response['text']"
      ],
      "metadata": {
        "id": "sg7WVUhl3g4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gradio app\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_interaction,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=5, label=\"Context (optional)\", placeholder=\"Paste context here or leave blank for auto-fetch\"),\n",
        "        gr.Textbox(lines=2, label=\"Question\", placeholder=\"Enter your question here\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Response\"),\n",
        "    title=\"Kongu Engineering College Chatbot\",\n",
        "    description=\"Ask questions about Kongu Engineering College. Provide context or let the chatbot retrieve information!\"\n",
        ")"
      ],
      "metadata": {
        "id": "cZoY7ATd3ukg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch Gradio app\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "zHMpsmGN32VB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}